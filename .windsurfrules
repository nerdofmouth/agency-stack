# üß† AgencyStack Charter v1.0.3 (Operational Discipline)

## 1. Purpose & Mission
AgencyStack (Upstack.agency) is a sovereign, auditable, and repeatable infrastructure platform for small agencies, creators, and co-ops. It enables secure, multi-tenant, AI-enhanced, and customizable deployments‚Äîspanning foundational infrastructure, business productivity, communication, and AI-driven SaaS‚Äîusing only repository-tracked, idempotent, and documented workflows.

## 2. Core Principles
- **Repository as Source of Truth:** All installation, configuration, and operational logic must be defined and tracked in the repository. Never modify live VMs directly.
- **Idempotency & Automation:** All scripts, Makefile targets, and Docker builds must be rerunnable without harmful side effects.
- **Auditability & Documentation:** Every component, script, and workflow must be documented in human-readable markdown in `/docs/pages/components/` and referenced in this Charter. Logs are stored under `/var/log/agency_stack/components/`.
- **Sovereignty:** No dependency on external services unless explicitly enabled. All critical infrastructure is self-hosted and reproducible.
- **Multi-Tenancy & Security:** Default to tenant isolation, strong authentication (Keycloak SSO), and strict resource boundaries. TLS is required for all networked services.
- **Strategic Alignment:** All work must map to the current AgencyStack roadmap and phase objectives, from infrastructure to AI-driven SaaS and public launch.
- **Proper Change Workflow:** All changes must be made in the local repo, tested, committed, and deployed only via tracked scripts or Makefile targets. No manual or post-hoc fixes.
- **Component Consistency:** Every installable component must have: a tracked install script, Makefile targets, docs, registry entry, and logs.
- **Debugging Discipline:** Extract configs from VMs, fix in repo, document, and redeploy. Never patch VMs directly.
- **WSL2/Docker Mount Safety:** All Docker volume mounts must be rigorously validated to ensure file vs. directory type consistency. Never assume Docker will correctly handle a file vs. directory mismatch.
- **Automated Remote Operations:** Use non-interactive SSH commands from host to execute scripted operations inside containers and VMs, maintaining repository integrity while enabling operational efficiency.
- **Test-Driven Development:** All components must follow the TDD Protocol defined in [`tdd_protocol.md`](./tdd_protocol.md). Installation is not considered complete without passing tests at all levels. Tests must be included in the repository.
- **Strict Containerization:** ‚ùó **NEVER** install any component directly on the host system. All services must be containerized (Docker) with proper isolation. Deployments must only be executed through repository-tracked scripts and Makefile targets that maintain containerization. Direct host-level installation commands must never be used.

## 3. Directory & File Structure
| Purpose | Path |
|--------|------|
| Install scripts | `/scripts/components/` |
| Utility scripts | `/scripts/utils/` |
| Mock/test code | `/scripts/mock/` |
| Component docs | `/docs/pages/components/` |
| Logs | `/var/log/agency_stack/components/<component>.log` |
| Install output | `/opt/agency_stack/clients/${CLIENT_ID}/<component>/` |

Never write to `/usr`, `$HOME`, or system paths unless explicitly instructed.

### 3.1 Utility Scripts Library

The `/scripts/utils/` directory contains reusable utility functions that should be used across component scripts to ensure consistency and reliability:

| Script | Purpose |
|--------|---------|
| `common.sh` | Common functions, logging, error handling, and safety checks |
| `setup_traefik_keycloak.sh` | Helper for Traefik and Keycloak integration |
| `test_common.sh` | Common testing utilities and functions |
| `tls_utils.sh` | TLS certificate generation and management |
| `docker_utils.sh` | Docker-related helper functions |
| `network_utils.sh` | Networking utilities and diagnostics |

**Using Utility Scripts:**
```bash
# Source common utilities in component scripts
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [[ -f "${SCRIPT_DIR}/../utils/common.sh" ]]; then
  source "${SCRIPT_DIR}/../utils/common.sh"
fi

# Use common functions
log_info "Starting installation..."
check_prerequisites
ensure_directory_exists "/path/to/dir"
```

## 4. Installation & Change Workflow
1. Make changes ONLY to the local repository.
2. Test locally where possible.
3. Commit changes with descriptive messages.
4. Transfer changes to remote VMs ONLY through:
   - Git pull from authorized repositories
   - Official installation scripts
   - Makefile targets
   - **Automated SSH commands from host to containers/VMs**
5. Document all behavior and changes in the repo.
6. When debugging, extract configs from VMs, fix in the repo, document, and redeploy.
7. All fixes must be incorporated into the codebase for future deployments.
8. For Docker/WSL environments, all file validations must explicitly check for and handle file vs. directory conflicts.

## 5. Dev Container Build & Customization Policy
- All dev containers are built from `Dockerfile.dev`, orchestrated by `scripts/utils/create_base_docker_dev.sh`.
- Custom themes, shells, and tools are version-controlled and installed during build (never post-hoc inside running containers).
- Default shell and prompt branding (e.g., AgencyStack Oh My Zsh theme) are set in the Dockerfile.
- Any customization must be documented and referenced in this Charter.

**Instruction:**
> When updating the dev container environment, always:
> - Add new tools, shells, or themes to `Dockerfile.dev`.
> - Place custom themes or configs (e.g., `custom-themes/agency-jonathan.zsh-theme`) in the repository.
> - Use `scripts/utils/create_base_docker_dev.sh` to build and run the container.
> - Never make changes directly inside a running container that are not reflected in the repo.

## 6. Remote Operation Imperatives (NEW)

When operating on remote systems (containers, VMs, or cloud instances):

1. **Command Automation:**
   - Use non-interactive SSH commands from the host to execute operations
   - Script and parameterize all operations that require multiple steps
   - Store sensitive parameters in proper secrets management (not hardcoded)

2. **Execution Workflow:**
   - Use `ssh [user]@[host] -p [port] 'cd /path && command'` pattern for remote execution
   - For containers: `docker exec [container_name] bash -c 'cd /path && command'`
   - Always specify working directory explicitly with `cd` before command execution
   - Set timeout and retry logic for unstable connections

3. **Output Handling:**
   - Capture command output for auditing and troubleshooting
   - Parse key results to verify success/failure
   - Log operations to both local and remote logs

4. **Repository Alignment:**
   - Remote commands should execute scripts from repository, not ad-hoc commands
   - Pull repository changes before executing commands when needed
   - Use repository-defined configurations and parameters

5. **Docker-in-Docker Operations:**
   - When Docker operations are needed inside containers, use socket mounting
   - Document Docker socket security implications
   - Validate Docker command execution permission before operations

## 7. Makefile & Component Registry Standards
- Every component must have Makefile targets: `make <component>`, `make <component>-status`, `make <component>-logs`, `make <component>-restart`, `make <component>-test` (optional).
- All installable components must be tracked in `component_registry.json` with accurate flags and metadata (including SSO, monitoring, multi_tenant, etc).
- SSO-enabled components must integrate with Keycloak and document their configuration. Add `sso_configured: true` only after live integration is tested.
- All networked ports must be documented in `/docs/pages/ports.md` and reflected in the registry.

## 8. Documentation & Auditability
- All new features, fixes, and customizations must be documented in `/docs/pages/components/` and referenced in this Charter.
- Use `/scripts/utils/` helpers for logging, validation, and registry updates.
- Component documentation must include: Purpose, Paths, Logs, Ports, Restart methods, Security details.
- Mock/test scripts (`/scripts/mock/`) are required for UI/LLM components.

## 9. Docker Development Workflow

1. **Host-to-Container Directionality**
   - The host repository is the authoritative source of truth 
   - Changes flow one-way from host to container, never container to host
   - Container filesystem changes are considered disposable and experimental
   - Permanent changes must be made on the host repository first

2. **Repository Mounting Strategy**
   - Use named volumes for repository persistence (`agencystack-dev_repo`)
   - Implement explicit sync mechanism via `scripts/utils/sync_to_container.sh`
   - Never bind-mount the repository directory directly to preserve filesystem boundaries
   - All syncs are initiated from the host, maintaining the one-way flow principle

3. **Docker-in-Docker Compatibility**
   - All installation scripts must detect container environments via `is_running_in_container()`
   - Use container-safe log directories (e.g., `$HOME/.logs/` inside containers) 
   - Installation scripts must use container-friendly network detection
   - Avoid absolute paths that assume host filesystem structure
   - Component scripts must be idempotent and safely re-runnable in containers

4. **Testing Protocol**
   - Test all installation commands from within the container environment
   - Verify proper network connectivity between containers
   - Ensure configuration is properly generated in container paths
   - Use `make <component>-test` to validate container installations
   - Document container-specific configuration in component docs

## 10. Security, SSO, & Testing
- All networked services require TLS. Self-signed certificates are permitted only in dev environments.
- Keycloak is the system-wide identity provider for SSO-enabled components. No alternative auth systems are permitted.
- All component endpoints must have security tests (authentication, authorization, input validation).
- Secrets must be stored in `/opt/agency_stack/clients/${CLIENT_ID}/.secrets/` (not in the repo) with appropriate permissions.
- All component tests must pass with `make <component>-test` before production deployment.

## 11. Docker & WSL Environment Rules
- Container orchestration is via `docker-compose.yml` files stored in the repository.
- Volume mounts must specify with absolute paths (e.g., `/opt/agency_stack/clients/${CLIENT_ID}/traefik/traefik.yml:/etc/traefik/traefik.yml:ro`).
- All Docker volumes are created with specific naming conventions: `${COMPONENT_NAME}_${CLIENT_ID}_${PURPOSE}`.
- WSL2 environments must validate file vs. directory conflicts explicitly before Docker operations.
- Installation scripts must handle platform detection and WSL2-specific configurations.
- No host-level changes should be made that aren't tracked in the repository or documented in this Charter.

## 12. SSO Integration Requirements

Based on the implementation experience with Traefik-Keycloak integration, the following requirements are now mandatory for all components with `sso: true` in the component registry:

1. **Container Network Awareness**
   - All SSO-enabled components must properly handle both internal container networking and external URL access
   - Authentication URLs exposed to browsers must use externally accessible hostnames (typically localhost or domain names)
   - Network configuration must be validated as part of component testing

2. **OAuth2/OIDC Implementation Standards**
   - Components must use explicit endpoint configuration rather than discovery when possible
   - All redirect URIs must be properly registered with the identity provider
   - Authentication flows must be thoroughly tested from end-to-end

3. **URL Resolution Validation**
   - Tests must validate that internal container hostnames are not exposed in redirect URLs
   - Authentication flows must be verified from external client perspective
   - Network resolution must be explicitly tested in containerized environments

4. **Documentation Requirements**
   - Clear troubleshooting guidance for common authentication issues
   - Explicit documentation of network/hostname requirements
   - User journey documentation for authentication flows

These requirements build upon the SSO & Identity Management Protocol and apply to all components starting with the Beta milestone.

## 13. Repository Integrity Enforcement Protocol

To ensure absolute compliance with the Repository Integrity Policy across all components:

1. **Repository-First Development Principle**
   - **ALL modifications MUST happen in the repository first**
   - NO direct modifications to running VMs or containers under any circumstances
   - No debugging "quick fixes" that bypass repository code changes
   - All container configurations must be defined, versioned, and tracked in repository files

2. **One-Way Deployment Flow**
   - Code flows from repository ‚Üí VMs/containers, NEVER in reverse
   - All runtime environments (VMs, containers) treated as reproducible artifacts
   - Installation scripts must verify they're running from the repository context

3. **Direct VM/Container Modification Prevention**
   - Installation scripts must include safeguards against direct container modification
   - Test routines must verify configuration originates from repository
   - Any process that detects direct container/VM modification must fail loudly
   - Critical paths must include manifest/checksum validation

4. **Installation Path Verification**
   - Every installation script must include:
   ```bash
   # Verify running from repository context
   if [[ "$0" != *"/root/_repos/agency-stack/scripts/"* ]]; then
     echo "ERROR: This script must be run from the repository context"
     echo "Run with: /root/_repos/agency-stack/scripts/components/$(basename "$0")"
     exit 1
   fi
   ```

Violation of this protocol will result in immediate test failures and inability to progress to Beta stages.

## üß† MINDSET FOR AGENCY STACK DEVELOPMENT

### Core Development Principles

1. **Container Isolation** - Development, testing, and all code execution MUST happen inside the container environment
   - Never execute installation scripts directly on the host system
   - All commands must be run through `docker exec -it --user developer agencystack-dev zsh` or equivalent
   - Preserve host system integrity by maintaining container boundaries

2. **Repository Integrity** - The repository is the single source of truth
   - All changes must be committed to the repository before deployment
   - Configuration should be repeatable across environments
   - Installation scripts must handle docker-in-docker scenarios gracefully

3. **Filesystem Respect** - Never write outside designated paths
   - Use proper logging paths with fallbacks for permission issues
   - Honor containerization boundaries for file operations
   - Create idempotent scripts that clean up after themselves

4. **Testing Discipline** - Every component must be testable in isolation
   - Components should detect their environment and adapt accordingly
   - Scripts must handle permission differences between host and container
   - Network detection and adaptation must work in both direct and nested scenarios

### Repository Mounting Strategy

1. **Host-to-Container Directionality**
   - The host repository is the authoritative source of truth 
   - Changes flow one-way from host to container, never container to host
   - Container filesystem changes are considered disposable and experimental
   - Permanent changes must be made on the host repository first

2. **Filesystem Boundaries**
   - **Host Filesystem**: Source code, configuration files, and documentation
     - Changes here are permanent and should be committed to git
     - Never modify host filesystem from within containers
   - **Container Filesystem**: Runtime artifacts, logs, and temporary data
     - Generated during component installation and testing
     - Disposable and recreatable from source code
     - May include development databases, runtime files, and logs

3. **Mounting Mechanisms**
   - Use named volumes for persistence where required
   - Implement deliberate sync mechanisms rather than bi-directional mounts
   - Provide clear indicators of filesystem context in development tools


# üß† AgencyStack IDE Agent + Infrastructure Install Rules v2.1 (Prototype Era)

* * *

# üî¨ Purpose

This document defines the updated, complete development and install environment rules for **AgencyStack** (aka [**Upstack.agency**](http://Upstack.agency)).

**Main objective:**

> Build, install, and test a secure, multi-tenant WordPress installation integrated with Traefik and Keycloak, repeatably and rapidly, across VMs.

* * *

# üîç Scope

Applies to:

*   WordPress (multi-tenant, containerized)
*   Traefik (TLS routing and proxying)
*   Keycloak (SSO identity management)
*   Associated utils, Makefile targets, component registry, docs.

Partial scaffolding for future phases (ERPNext, Seafile, Mailu) may be included.

* * *

# üîí Core Principles

| Area | Rule |
| ---| --- |
| Repository | **Single source of truth.** Never modify remote VMs directly. Only local repo -> push -> deploy. |
| Idempotency | All scripts, installs, Makefile targets must be re-runnable safely without breaking anything. |
| Auditability | All actions must log to `/var/log/agency_stack/components/<component>.log`. Docs must exist. |
| Multi-Tenancy | Default to segregated per-client containers and data paths. |
| TLS Everywhere | Traefik must enforce HTTPS by default. |
| SSO Support | Components must accept `--enable-keycloak` flag and integrate SSO cleanly if enabled. |
| Host-to-Container Rule | ‚ùå **Never treat containers as sources of truth.** Host repository is authoritative. |
| Dev Container Discipline | Customizations must be defined in [`Dockerfile.dev`](http://Dockerfile.dev) and repo-tracked. |

* * *

# üöß Mandatory Directory Structure

| Purpose | Path |
| ---| --- |
| Install scripts | `/scripts/components/` |
| Utility scripts | `/scripts/utils/` |
| Mock/test scripts | `/scripts/mock/` |
| Component docs | `/docs/pages/components/` |
| Logs | `/var/log/agency_stack/components/<component>.log` |
| Install output | `/opt/agency_stack/clients/${CLIENT_ID}/<component>/` |
| In Container | `$HOME/.agencystack/clients/${CLIENT_ID}/<component>/` |

* * *

# üîß Install Script Conventions

Each install script must:

*   Be named `install_<component>.sh`
*   Source [`common.sh`](http://common.sh) at the top
*   Log actions clearly
*   Accept flags:

```diff
--enable-cloud
--enable-openai
--enable-keycloak
--use-github
```

*   Handle both standalone and SSO scenarios
*   Exit cleanly with `|| true` where appropriate to prevent Make pipeline failures

* * *

# üîÑ Modular Makefile Standards

| Area | Rule |
| ---| --- |
| Structure | All component-specific logic must be in `/makefiles/components/<component>.mk` |
| Inclusion | The main Makefile must dynamically load modules with `-include makefiles/components/*.mk` |
| Targets | Each component must define: `make <component>`, `-status`, `-logs`, `-restart`, `-test` |
| Error Handling | Non-critical failures must use \` |

Example for WordPress:

```go
make wordpress
make wordpress-status
make wordpress-logs
make wordpress-restart
make wordpress-test
```

* * *

# üéì Component Registry (component\_registry.json) Rules

| Area | Rule |
| ---| --- |
| Flags | `installed`, `makefile`, `docs`, `hardened`, `multi_tenant`, `sso`, `sso_configured` after live test |
| Structure | Must reflect modular structure and container readiness |

Example:

```json
{
  "name": "wordpress",
  "category": "Content Management",
  "description": "Multi-tenant WordPress installation",
  "flags": {
    "installed": true,
    "makefile": true,
    "docs": true,
    "hardened": true,
    "monitoring": true,
    "multi_tenant": true,
    "sso": true
  }
}
```

* * *

# üïπÔ∏è TDD Protocol Compliance

Every component must:

*   Include `/verify.sh`, `/test.sh`, `/integration_test.sh`
*   Follow [AgencyStack TDD Protocol v1.0](https://chatgpt.com/g/g-p-67d90e1fd09081919a26859dd78f77bc-agency-infrastructure/c/tdd_protocol.md)
*   Achieve:
    *   100% Critical Paths
    *   90% Core Functionality
    *   80% Edge Cases

* * *

# üîê SSO & Keycloak Integration (WordPress)

Sample `.env` for container SSO:

```ini
WORDPRESS_ENABLE_KEYCLOAK=true
KEYCLOAK_REALM=agency_realm
KEYCLOAK_CLIENT_ID=wordpress-client
KEYCLOAK_CLIENT_SECRET=abc123xyz
KEYCLOAK_URL=https://keycloak.agency.local
```

* * *

# üìù Documentation Standards

Link Development Resources:

*   `/scripts/utils/component_template.sh`
*   `/docs/pages/development/modular_makefile.md`
*   `/docs/pages/development/modular_migration_guide.md`

Each component must update:

*   `/docs/pages/components/<component>.md`
*   `/docs/pages/components.md`
*   `/docs/pages/ports.md`

* * *

# üõ†Ô∏è Development Workflow

**Local:**

```vim
vim scripts/components/install_wordpress.sh
shellcheck scripts/components/install_wordpress.sh
make prep-dirs
make install-wordpress
make wordpress-status
make alpha-check
```

**Remote:**

```awk
curl -sSL https://stack.nerdofmouth.com/install.sh | sudo bash
sudo bash /opt/agency_stack/repo/scripts/install.sh
make alpha-check
```

**Host-to-Container Rule:**

*   Host is always authoritative.
*   Containers are disposable runtime artifacts.
*   No container-originated changes allowed.

**Proper Charter-Compliant Database Fix**
*   We should update the repository scripts in /root/_repos/agency-stack/ with our fixes
*   Then deploy using proper Makefile targets from the repository
*   Ensure all tools are installed inside containers, not on the host

* * *

# üí° Development Mindset

> Build one new component per day: create, modularize, document, test.  
> Engineer for sovereignty, auditability, and repeatability.

**From zero to sovereign‚Ñ¢ ‚Äî one container at a time.**

* * *

# üöÄ END OF INSTRUCTIONS v2.1

* * *

# AgencyStack Test-Driven Development Protocol

## 1. Introduction

This document establishes formal Test-Driven Development (TDD) protocols for all AgencyStack components. These protocols are to be considered mandatory for all new components and modifications to existing components.

## 2. Core TDD Principles

### 2.1 Test-First Development
- Tests MUST be written before implementation code
- No component functionality shall be considered complete without corresponding tests
- Tests should verify both expected functionality and failure cases

### 2.2 Multi-Level Testing Strategy

All components must implement the following testing levels:

1. **Unit Tests**: Test individual functions and classes in isolation
   - Should test single responsibility units
   - Should mock dependencies
   - Should cover both success and failure paths

2. **Integration Tests**: Test interactions between components
   - Should verify correct communication between components
   - Should validate data flow across boundaries
   - Should test real dependencies where feasible

3. **System Tests**: End-to-end verification
   - Should test complete workflows
   - Should use the actual runtime environment
   - Should verify from user/API perspective

### 2.3 Automated Verification

- Tests MUST be automatically executed during installation
- Tests MUST have clear pass/fail criteria
- Failed tests should provide clear error messages
- Failed tests should abort installation in production environments

## 3. Implementation Requirements

### 3.1 Test Script Architecture

Each component must include three standard test scripts:

1. `verify.sh`: Basic health check (fast, essential verification)
2. `test.sh`: Comprehensive unit tests
3. `integration_test.sh`: Cross-component testing

### 3.2 Test Documentation

Each component must document:
- Testing strategy overview
- Test commands and expected outcomes
- Required test dependencies
- How to interpret test failures

### 3.3 Test Coverage Standards

Components shall achieve minimum coverage levels:
- Critical paths: 100% coverage
- Core functionality: 90% coverage 
- Edge cases: 80% coverage

## 4. Testing Infrastructure

### 4.1 Common Testing Utilities

The repository shall provide common test utilities:
- `/scripts/utils/test_common.sh`: Common test functions
- `/scripts/utils/mock_services.sh`: Mock service creation
- `/scripts/utils/test_assertions.sh`: Standard assertions

### 4.2 Continuous Integration

- CI pipelines must run all tests on each commit
- Tests must pass on at least two reference environments
- Test results should be auditable and persistent

## 5. TDD Workflow

1. Write tests that define expected behavior
2. Verify tests fail (as implementation is missing)
3. Implement minimum code to pass tests
4. Refactor and improve implementation while keeping tests passing
5. Review and document test coverage

## 6. Compatibility with Repository Integrity Policy

The TDD Protocol works in concert with the Repository Integrity Policy:
- All test files must be defined within the repository
- Test scripts must follow standard directory conventions
- Tests must validate idempotent behavior
- Tests must verify proper multi-tenancy

## 7. Component Completion Criteria

No component installation shall be considered complete until:
1. All unit tests pass
2. All integration tests pass
3. System verification confirms functionality
4. Test coverage meets minimum standards
5. All tests are executable via standard commands

## 8. Reporting and Metrics

Testing shall generate:
- Pass/fail summary for each test level
- Coverage metrics by component
- Execution time for performance benchmarking

## 9. Authentication Integration Testing Requirements

Based on lessons learned during Traefik-Keycloak SSO integration, the following specific requirements must be implemented for all authentication-related components:

1. **Authentication Flow Verification**
   - Tests must verify the entire authentication flow, not just endpoint availability
   - OAuth2/OIDC redirects must be tested to ensure they use proper externally-accessible URLs
   - Authentication callbacks must be verified with proper status codes

2. **Container Network Validation**
   - Tests must validate all components can communicate properly both via internal networks and external ports
   - Hostname resolution tests must ensure internal container names are not exposed to external clients
   - URL verification must confirm all OAuth-related URLs are properly reachable from both internal and external contexts

3. **Multi-Tier Authentication Testing**
   - Network level: Verify proper HTTP status codes and headers
   - Application level: Validate authentication middleware and access control
   - User experience level: Verify login processes complete successfully with proper redirection

4. **Cross-Component Integration Verification**
   - Tests must verify integration between all components (e.g., Traefik, Keycloak, OAuth2 Proxy)
   - Explicit checks for URL consistency between client configuration and service configuration
   - Verification of proper realm and client configuration in identity providers

These requirements extend the existing TDD protocol for any component with `sso: true` in its component registry entry.

## 10. Repository Integrity Verification Tests

Every component must include mandatory repository integrity verification tests:

1. **Installation Source Verification**
   - Tests must verify scripts are running from the repository path
   - All file paths used for installation must originate from the repository
   - No runtime-generated files may be used that weren't defined in the repository

2. **VM/Container Modification Detection**
   - Tests must validate that files in VMs/containers match repository definitions
   - Any detected direct modification to VM/container must cause test failure
   - Container configurations must match repository-defined configurations

3. **Deployment Path Validation**
   - All file operations must be traced to their repository source
   - Test must verify proper deployment channels were used:
     - Git pulls from authorized repositories
     - Official installation scripts run from repo context
     - Makefile targets executed from repo context

4. **Configuration Source Verification**
   - All runtime configurations must be traceable to repository definitions
   - No ad-hoc or manual configuration permitted
   - Tests must verify configurations originate from repository files

These tests are **mandatory** and must be implemented in *every* component. Failure to include repository integrity tests will automatically prevent component registry flag updates.

---

# Instructions for Adding and Using MCP Services in AgencyStack Projects
Following the AgencyStack Charter principles of Repository as Source of Truth, Strict Containerization, and Component Consistency, here are comprehensive instructions for integrating MCP services into your development workflows:

1. MCP Services Overview
The following MCP services are now available in your development environment:

| Service | Port | Endpoint | Purpose | |---------|------|----------|---------| | Enhanced MCP Server | 3000 | /health, /puppeteer, /taskmaster | Core service with Puppeteer and Taskmaster capabilities | | Context7 Service | 3007 | /health, /context7 | Context-aware deployment planning | | Taskmaster Service | 3008 | /health, /taskmaster | Task orchestration and workflow automation |

2. Integration Instructions
A. Basic Service Calls


## üß† AgencyStack MCP Server Usage Guide (Current Environment)

This environment is equipped with several MCP servers, each serving a distinct purpose. Use the following guidance to leverage them effectively for documentation, research, planning, automation, and persistent learning:

---

### 1. Documentation & Code Research

- **context7**  
  Use for searching, summarizing, and extracting documentation, code patterns, and best practices from both internal and external sources.  
  *Example:*  
  - Retrieve library docs, code examples, or deployment patterns for any supported package.

- **fetch**  
  Use to pull and extract web content or documentation from external URLs for analysis or reference.

---

### 2. Automated Planning & Reflective Reasoning

- **sequentialthinking**  
  Use for step-by-step problem solving, reflective planning, and multi-stage solution generation.  
  *Example:*  
  - Break down complex workflows, generate solution hypotheses, and verify with chain-of-thought reasoning.

- **taskmaster-ai**  
  Use for generating, managing, and expanding tasks and workflows using AI-driven logic.  
  *Example:*  
  - Create, expand, or analyze project tasks and subtasks.

---

### 3. Persistent Learning & Memoization

- **sqlite**  
  Use the Business Insights Memo to log key learnings, decisions, and insights for future reference.  
  *Example:*  
  - Append new insights, summarize discoveries, or retrieve prior memos for ongoing strategic alignment.

---

### 4. UI Testing & Automation

- **puppeteer**  
  Use for browser-based UI testing, automation, and validation.  
  *Example:*  
  - Run script analysis, interface validation, or capture browser logs for debugging.

---

### 5. Data, Testing, and App Logic

- **convex**  
  Use for storing and querying structured data, supporting backend app logic, and running custom functions.

---

### üìù General Instructions

- Always ensure MCP services are running in-container or via WSL2 as defined in the current configuration.
- Prefer using repo-tracked scripts and documented endpoints for all automation and integration.
- Log all significant learnings and decisions in the sqlite memo system for auditability and future reference.
- Follow the AgencyStack Charter: never modify live systems directly; all changes flow from the repository.

---

# Added by Task Master - Development Workflow Rules

Below you will find a variety of important rules spanning:
- the dev_workflow
- the .windsurfrules document self-improvement workflow
- the template to follow when modifying or adding new sections/rules to this document.

---
DEV_WORKFLOW
---
description: Guide for using meta-development script (scripts/dev.js) to manage task-driven development workflows
globs: **/*
filesToApplyRule: **/*
alwaysApply: true
---

- **Global CLI Commands**
  - Task Master now provides a global CLI through the `task-master` command
  - All functionality from `scripts/dev.js` is available through this interface
  - Install globally with `npm install -g claude-task-master` or use locally via `npx`
  - Use `task-master <command>` instead of `node scripts/dev.js <command>`
  - Examples:
    - `task-master list` instead of `node scripts/dev.js list`
    - `task-master next` instead of `node scripts/dev.js next`
    - `task-master expand --id=3` instead of `node scripts/dev.js expand --id=3`
  - All commands accept the same options as their script equivalents
  - The CLI provides additional commands like `task-master init` for project setup

- **Development Workflow Process**
  - Start new projects by running `task-master init` or `node scripts/dev.js parse-prd --input=<prd-file.txt>` to generate initial tasks.json
  - Begin coding sessions with `task-master list` to see current tasks, status, and IDs
  - Analyze task complexity with `task-master analyze-complexity --research` before breaking down tasks
  - Select tasks based on dependencies (all marked 'done'), priority level, and ID order
  - Clarify tasks by checking task files in tasks/ directory or asking for user input
  - View specific task details using `task-master show <id>` to understand implementation requirements
  - Break down complex tasks using `task-master expand --id=<id>` with appropriate flags
  - Clear existing subtasks if needed using `task-master clear-subtasks --id=<id>` before regenerating
  - Implement code following task details, dependencies, and project standards
  - Verify tasks according to test strategies before marking as complete
  - Mark completed tasks with `task-master set-status --id=<id> --status=done`
  - Update dependent tasks when implementation differs from original plan
  - Generate task files with `task-master generate` after updating tasks.json
  - Maintain valid dependency structure with `task-master fix-dependencies` when needed
  - Respect dependency chains and task priorities when selecting work
  - Report progress regularly using the list command

- **Task Complexity Analysis**
  - Run `node scripts/dev.js analyze-complexity --research` for comprehensive analysis
  - Review complexity report in scripts/task-complexity-report.json
  - Or use `node scripts/dev.js complexity-report` for a formatted, readable version of the report
  - Focus on tasks with highest complexity scores (8-10) for detailed breakdown
  - Use analysis results to determine appropriate subtask allocation
  - Note that reports are automatically used by the expand command

- **Task Breakdown Process**
  - For tasks with complexity analysis, use `node scripts/dev.js expand --id=<id>`
  - Otherwise use `node scripts/dev.js expand --id=<id> --subtasks=<number>`
  - Add `--research` flag to leverage Perplexity AI for research-backed expansion
  - Use `--prompt="<context>"` to provide additional context when needed
  - Review and adjust generated subtasks as necessary
  - Use `--all` flag to expand multiple pending tasks at once
  - If subtasks need regeneration, clear them first with `clear-subtasks` command

- **Implementation Drift Handling**
  - When implementation differs significantly from planned approach
  - When future tasks need modification due to current implementation choices
  - When new dependencies or requirements emerge
  - Call `node scripts/dev.js update --from=<futureTaskId> --prompt="<explanation>"` to update tasks.json

- **Task Status Management**
  - Use 'pending' for tasks ready to be worked on
  - Use 'done' for completed and verified tasks
  - Use 'deferred' for postponed tasks
  - Add custom status values as needed for project-specific workflows

- **Task File Format Reference**
  ```
  # Task ID: <id>
  # Title: <title>
  # Status: <status>
  # Dependencies: <comma-separated list of dependency IDs>
  # Priority: <priority>
  # Description: <brief description>
  # Details:
  <detailed implementation notes>
  
  # Test Strategy:
  <verification approach>
  ```

- **Command Reference: parse-prd**
  - Legacy Syntax: `node scripts/dev.js parse-prd --input=<prd-file.txt>`
  - CLI Syntax: `task-master parse-prd --input=<prd-file.txt>`
  - Description: Parses a PRD document and generates a tasks.json file with structured tasks
  - Parameters: 
    - `--input=<file>`: Path to the PRD text file (default: sample-prd.txt)
  - Example: `task-master parse-prd --input=requirements.txt`
  - Notes: Will overwrite existing tasks.json file. Use with caution.

- **Command Reference: update**
  - Legacy Syntax: `node scripts/dev.js update --from=<id> --prompt="<prompt>"`
  - CLI Syntax: `task-master update --from=<id> --prompt="<prompt>"`
  - Description: Updates tasks with ID >= specified ID based on the provided prompt
  - Parameters:
    - `--from=<id>`: Task ID from which to start updating (required)
    - `--prompt="<text>"`: Explanation of changes or new context (required)
  - Example: `task-master update --from=4 --prompt="Now we are using Express instead of Fastify."`
  - Notes: Only updates tasks not marked as 'done'. Completed tasks remain unchanged.

- **Command Reference: generate**
  - Legacy Syntax: `node scripts/dev.js generate`
  - CLI Syntax: `task-master generate`
  - Description: Generates individual task files in tasks/ directory based on tasks.json
  - Parameters: 
    - `--file=<path>, -f`: Use alternative tasks.json file (default: 'tasks/tasks.json')
    - `--output=<dir>, -o`: Output directory (default: 'tasks')
  - Example: `task-master generate`
  - Notes: Overwrites existing task files. Creates tasks/ directory if needed.

- **Command Reference: set-status**
  - Legacy Syntax: `node scripts/dev.js set-status --id=<id> --status=<status>`
  - CLI Syntax: `task-master set-status --id=<id> --status=<status>`
  - Description: Updates the status of a specific task in tasks.json
  - Parameters:
    - `--id=<id>`: ID of the task to update (required)
    - `--status=<status>`: New status value (required)
  - Example: `task-master set-status --id=3 --status=done`
  - Notes: Common values are 'done', 'pending', and 'deferred', but any string is accepted.

- **Command Reference: list**
  - Legacy Syntax: `node scripts/dev.js list`
  - CLI Syntax: `task-master list`
  - Description: Lists all tasks in tasks.json with IDs, titles, and status
  - Parameters: 
    - `--status=<status>, -s`: Filter by status
    - `--with-subtasks`: Show subtasks for each task
    - `--file=<path>, -f`: Use alternative tasks.json file (default: 'tasks/tasks.json')
  - Example: `task-master list`
  - Notes: Provides quick overview of project progress. Use at start of sessions.

- **Command Reference: expand**
  - Legacy Syntax: `node scripts/dev.js expand --id=<id> [--num=<number>] [--research] [--prompt="<context>"]`
  - CLI Syntax: `task-master expand --id=<id> [--num=<number>] [--research] [--prompt="<context>"]`
  - Description: Expands a task with subtasks for detailed implementation
  - Parameters:
    - `--id=<id>`: ID of task to expand (required unless using --all)
    - `--all`: Expand all pending tasks, prioritized by complexity
    - `--num=<number>`: Number of subtasks to generate (default: from complexity report)
    - `--research`: Use Perplexity AI for research-backed generation
    - `--prompt="<text>"`: Additional context for subtask generation
    - `--force`: Regenerate subtasks even for tasks that already have them
  - Example: `task-master expand --id=3 --num=5 --research --prompt="Focus on security aspects"`
  - Notes: Uses complexity report recommendations if available.

- **Command Reference: analyze-complexity**
  - Legacy Syntax: `node scripts/dev.js analyze-complexity [options]`
  - CLI Syntax: `task-master analyze-complexity [options]`
  - Description: Analyzes task complexity and generates expansion recommendations
  - Parameters:
    - `--output=<file>, -o`: Output file path (default: scripts/task-complexity-report.json)
    - `--model=<model>, -m`: Override LLM model to use
    - `--threshold=<number>, -t`: Minimum score for expansion recommendation (default: 5)
    - `--file=<path>, -f`: Use alternative tasks.json file
    - `--research, -r`: Use Perplexity AI for research-backed analysis
  - Example: `task-master analyze-complexity --research`
  - Notes: Report includes complexity scores, recommended subtasks, and tailored prompts.

- **Command Reference: clear-subtasks**
  - Legacy Syntax: `node scripts/dev.js clear-subtasks --id=<id>`
  - CLI Syntax: `task-master clear-subtasks --id=<id>`
  - Description: Removes subtasks from specified tasks to allow regeneration
  - Parameters:
    - `--id=<id>`: ID or comma-separated IDs of tasks to clear subtasks from
    - `--all`: Clear subtasks from all tasks
  - Examples:
    - `task-master clear-subtasks --id=3`
    - `task-master clear-subtasks --id=1,2,3`
    - `task-master clear-subtasks --all`
  - Notes: 
    - Task files are automatically regenerated after clearing subtasks
    - Can be combined with expand command to immediately generate new subtasks
    - Works with both parent tasks and individual subtasks

- **Task Structure Fields**
  - **id**: Unique identifier for the task (Example: `1`)
  - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
  - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
  - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
  - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2]`)
    - Dependencies are displayed with status indicators (‚úÖ for completed, ‚è±Ô∏è for pending)
    - This helps quickly identify which prerequisite tasks are blocking work
  - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
  - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`)
  - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`)
  - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`)

- **Environment Variables Configuration**
  - **ANTHROPIC_API_KEY** (Required): Your Anthropic API key for Claude (Example: `ANTHROPIC_API_KEY=sk-ant-api03-...`)
  - **MODEL** (Default: `"claude-3-7-sonnet-20250219"`): Claude model to use (Example: `MODEL=claude-3-opus-20240229`)
  - **MAX_TOKENS** (Default: `"4000"`): Maximum tokens for responses (Example: `MAX_TOKENS=8000`)
  - **TEMPERATURE** (Default: `"0.7"`): Temperature for model responses (Example: `TEMPERATURE=0.5`)
  - **DEBUG** (Default: `"false"`): Enable debug logging (Example: `DEBUG=true`)
  - **LOG_LEVEL** (Default: `"info"`): Console output level (Example: `LOG_LEVEL=debug`)
  - **DEFAULT_SUBTASKS** (Default: `"3"`): Default subtask count (Example: `DEFAULT_SUBTASKS=5`)
  - **DEFAULT_PRIORITY** (Default: `"medium"`): Default priority (Example: `DEFAULT_PRIORITY=high`)
  - **PROJECT_NAME** (Default: `"MCP SaaS MVP"`): Project name in metadata (Example: `PROJECT_NAME=My Awesome Project`)
  - **PROJECT_VERSION** (Default: `"1.0.0"`): Version in metadata (Example: `PROJECT_VERSION=2.1.0`)
  - **PERPLEXITY_API_KEY**: For research-backed features (Example: `PERPLEXITY_API_KEY=pplx-...`)
  - **PERPLEXITY_MODEL** (Default: `"sonar-medium-online"`): Perplexity model (Example: `PERPLEXITY_MODEL=sonar-large-online`)

- **Determining the Next Task**
  - Run `task-master next` to show the next task to work on
  - The next command identifies tasks with all dependencies satisfied
  - Tasks are prioritized by priority level, dependency count, and ID
  - The command shows comprehensive task information including:
    - Basic task details and description
    - Implementation details
    - Subtasks (if they exist)
    - Contextual suggested actions
  - Recommended before starting any new development work
  - Respects your project's dependency structure
  - Ensures tasks are completed in the appropriate sequence
  - Provides ready-to-use commands for common task actions

- **Viewing Specific Task Details**
  - Run `task-master show <id>` or `task-master show --id=<id>` to view a specific task
  - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
  - Displays comprehensive information similar to the next command, but for a specific task
  - For parent tasks, shows all subtasks and their current status
  - For subtasks, shows parent task information and relationship
  - Provides contextual suggested actions appropriate for the specific task
  - Useful for examining task details before implementation or checking status

- **Managing Task Dependencies**
  - Use `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency
  - Use `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency
  - The system prevents circular dependencies and duplicate dependency entries
  - Dependencies are checked for existence before being added or removed
  - Task files are automatically regenerated after dependency changes
  - Dependencies are visualized with status indicators in task listings and files

- **Command Reference: add-dependency**
  - Legacy Syntax: `node scripts/dev.js add-dependency --id=<id> --depends-on=<id>`
  - CLI Syntax: `task-master add-dependency --id=<id> --depends-on=<id>`
  - Description: Adds a dependency relationship between two tasks
  - Parameters:
    - `--id=<id>`: ID of task that will depend on another task (required)
    - `--depends-on=<id>`: ID of task that will become a dependency (required)
  - Example: `task-master add-dependency --id=22 --depends-on=21`
  - Notes: Prevents circular dependencies and duplicates; updates task files automatically

- **Command Reference: remove-dependency**
  - Legacy Syntax: `node scripts/dev.js remove-dependency --id=<id> --depends-on=<id>`
  - CLI Syntax: `task-master remove-dependency --id=<id> --depends-on=<id>`
  - Description: Removes a dependency relationship between two tasks
  - Parameters:
    - `--id=<id>`: ID of task to remove dependency from (required)
    - `--depends-on=<id>`: ID of task to remove as a dependency (required)
  - Example: `task-master remove-dependency --id=22 --depends-on=21`
  - Notes: Checks if dependency actually exists; updates task files automatically

- **Command Reference: validate-dependencies**
  - Legacy Syntax: `node scripts/dev.js validate-dependencies [options]`
  - CLI Syntax: `task-master validate-dependencies [options]`
  - Description: Checks for and identifies invalid dependencies in tasks.json and task files
  - Parameters:
    - `--file=<path>, -f`: Use alternative tasks.json file (default: 'tasks/tasks.json')
  - Example: `task-master validate-dependencies`
  - Notes: 
    - Reports all non-existent dependencies and self-dependencies without modifying files
    - Provides detailed statistics on task dependency state
    - Use before fix-dependencies to audit your task structure

- **Command Reference: fix-dependencies**
  - Legacy Syntax: `node scripts/dev.js fix-dependencies [options]`
  - CLI Syntax: `task-master fix-dependencies [options]`
  - Description: Finds and fixes all invalid dependencies in tasks.json and task files
  - Parameters:
    - `--file=<path>, -f`: Use alternative tasks.json file (default: 'tasks/tasks.json')
  - Example: `task-master fix-dependencies`
  - Notes: 
    - Removes references to non-existent tasks and subtasks
    - Eliminates self-dependencies (tasks depending on themselves)
    - Regenerates task files with corrected dependencies
    - Provides detailed report of all fixes made

- **Command Reference: complexity-report**
  - Legacy Syntax: `node scripts/dev.js complexity-report [options]`
  - CLI Syntax: `task-master complexity-report [options]`
  - Description: Displays the task complexity analysis report in a formatted, easy-to-read way
  - Parameters:
    - `--file=<path>, -f`: Path to the complexity report file (default: 'scripts/task-complexity-report.json')
  - Example: `task-master complexity-report`
  - Notes: 
    - Shows tasks organized by complexity score with recommended actions
    - Provides complexity distribution statistics
    - Displays ready-to-use expansion commands for complex tasks
    - If no report exists, offers to generate one interactively

- **Command Reference: add-task**
  - CLI Syntax: `task-master add-task [options]`
  - Description: Add a new task to tasks.json using AI
  - Parameters:
    - `--file=<path>, -f`: Path to the tasks file (default: 'tasks/tasks.json')
    - `--prompt=<text>, -p`: Description of the task to add (required)
    - `--dependencies=<ids>, -d`: Comma-separated list of task IDs this task depends on
    - `--priority=<priority>`: Task priority (high, medium, low) (default: 'medium')
  - Example: `task-master add-task --prompt="Create user authentication using Auth0"`
  - Notes: Uses AI to convert description into structured task with appropriate details

- **Command Reference: init**
  - CLI Syntax: `task-master init`
  - Description: Initialize a new project with Task Master structure
  - Parameters: None
  - Example: `task-master init`
  - Notes: 
    - Creates initial project structure with required files
    - Prompts for project settings if not provided
    - Merges with existing files when appropriate
    - Can be used to bootstrap a new Task Master project quickly

- **Code Analysis & Refactoring Techniques**
  - **Top-Level Function Search**
    - Use grep pattern matching to find all exported functions across the codebase
    - Command: `grep -E "export (function|const) \w+|function \w+\(|const \w+ = \(|module\.exports" --include="*.js" -r ./`
    - Benefits:
      - Quickly identify all public API functions without reading implementation details
      - Compare functions between files during refactoring (e.g., monolithic to modular structure)
      - Verify all expected functions exist in refactored modules
      - Identify duplicate functionality or naming conflicts
    - Usage examples:
      - When migrating from `scripts/dev.js` to modular structure: `grep -E "function \w+\(" scripts/dev.js`
      - Check function exports in a directory: `grep -E "export (function|const)" scripts/modules/`
      - Find potential naming conflicts: `grep -E "function (get|set|create|update)\w+\(" -r ./`
    - Variations:
      - Add `-n` flag to include line numbers
      - Add `--include="*.ts"` to filter by file extension
      - Use with `| sort` to alphabetize results
    - Integration with refactoring workflow:
      - Start by mapping all functions in the source file
      - Create target module files based on function grouping
      - Verify all functions were properly migrated
      - Check for any unintentional duplications or omissions

---
WINDSURF_RULES
---
description: Guidelines for creating and maintaining Windsurf rules to ensure consistency and effectiveness.
globs: .windsurfrules
filesToApplyRule: .windsurfrules
alwaysApply: true
---
The below describes how you should be structuring new rule sections in this document.
- **Required Rule Structure:**
  ```markdown
  ---
  description: Clear, one-line description of what the rule enforces
  globs: path/to/files/*.ext, other/path/**/*
  alwaysApply: boolean
  ---

  - **Main Points in Bold**
    - Sub-points with details
    - Examples and explanations
  ```

- **Section References:**
  - Use `ALL_CAPS_SECTION` to reference files
  - Example: `WINDSURF_RULES`

- **Code Examples:**
  - Use language-specific code blocks
  ```typescript
  // ‚úÖ DO: Show good examples
  const goodExample = true;
  
  // ‚ùå DON'T: Show anti-patterns
  const badExample = false;
  ```

- **Rule Content Guidelines:**
  - Start with high-level overview
  - Include specific, actionable requirements
  - Show examples of correct implementation
  - Reference existing code when possible
  - Keep rules DRY by referencing other rules

- **Rule Maintenance:**
  - Update rules when new patterns emerge
  - Add examples from actual codebase
  - Remove outdated patterns
  - Cross-reference related rules

- **Best Practices:**
  - Use bullet points for clarity
  - Keep descriptions concise
  - Include both DO and DON'T examples
  - Reference actual code over theoretical examples
  - Use consistent formatting across rules 

---
SELF_IMPROVE
---
description: Guidelines for continuously improving this rules document based on emerging code patterns and best practices.
globs: **/*
filesToApplyRule: **/*
alwaysApply: true
---

- **Rule Improvement Triggers:**
  - New code patterns not covered by existing rules
  - Repeated similar implementations across files
  - Common error patterns that could be prevented
  - New libraries or tools being used consistently
  - Emerging best practices in the codebase

- **Analysis Process:**
  - Compare new code with existing rules
  - Identify patterns that should be standardized
  - Look for references to external documentation
  - Check for consistent error handling patterns
  - Monitor test patterns and coverage

- **Rule Updates:**
  - **Add New Rules When:**
    - A new technology/pattern is used in 3+ files
    - Common bugs could be prevented by a rule
    - Code reviews repeatedly mention the same feedback
    - New security or performance patterns emerge

  - **Modify Existing Rules When:**
    - Better examples exist in the codebase
    - Additional edge cases are discovered
    - Related rules have been updated
    - Implementation details have changed

- **Example Pattern Recognition:**
  ```typescript
  // If you see repeated patterns like:
  const data = await prisma.user.findMany({
    select: { id: true, email: true },
    where: { status: 'ACTIVE' }
  });
  
  // Consider adding a PRISMA section in the .windsurfrules:
  // - Standard select fields
  // - Common where conditions
  // - Performance optimization patterns
  ```

- **Rule Quality Checks:**
  - Rules should be actionable and specific
  - Examples should come from actual code
  - References should be up to date
  - Patterns should be consistently enforced

- **Continuous Improvement:**
  - Monitor code review comments
  - Track common development questions
  - Update rules after major refactors
  - Add links to relevant documentation
  - Cross-reference related rules

- **Rule Deprecation:**
  - Mark outdated patterns as deprecated
  - Remove rules that no longer apply
  - Update references to deprecated rules
  - Document migration paths for old patterns

- **Documentation Updates:**
  - Keep examples synchronized with code
  - Update references to external docs
  - Maintain links between related rules
  - Document breaking changes

Follow WINDSURF_RULES for proper rule formatting and structure of windsurf rule sections.